{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a new press\n",
    "\n",
    "In this guide, we will walk you through the process of creating a new press."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import pipeline\n",
    "\n",
    "from kvpress import BasePress, KnormPress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    }
   ],
   "source": [
    "# Load pipeline\n",
    "\n",
    "device = \"cuda:0\"\n",
    "ckpt = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "attn_implementation = \"flash_attention_2\"\n",
    "pipe = pipeline(\"kv-press-text-generation\", model=ckpt, device=device, torch_dtype=\"auto\", model_kwargs={\"attn_implementation\":attn_implementation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "context = \"In this step-by-step guide, you will learn how to create a new press in kvpress !\"\n",
    "question = \"\\nWhat is the purpose of this guide?\"\n",
    "tokens = pipe.tokenizer(context, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding how press work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A press registers a forward hook to each attention layer during the pre-filling phase:\n",
    "1. Immediately after the forward pass, the hook is called, and it computes a score for each key-value pair using the `press.score` method\n",
    "2. The key-value pairs with the lowest scores are then removed based on the `compression_ratio` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache shape w/o press: torch.Size([1, 2, 20, 128])\n",
      "Cache shape w/ press:  torch.Size([1, 2, 15, 128])\n",
      "\n",
      "The purpose of this step-by-step guide is to provide instructions on how to create a new press in kvpress. The guide is designed to help users understand the process of setting up a new press in the kvpress platform.\n"
     ]
    }
   ],
   "source": [
    "compression_ratio = 0.25\n",
    "press = KnormPress(compression_ratio)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs_without_press = pipe.model(**tokens, output_hidden_states=True)\n",
    "\n",
    "with torch.no_grad(), press(pipe.model):\n",
    "    output_with_press = pipe.model(**tokens)\n",
    "\n",
    "print(f\"Cache shape w/o press: {outputs_without_press.past_key_values[0][0].shape}\")\n",
    "print(f\"Cache shape w/ press:  {output_with_press.past_key_values[0][0].shape}\\n\")\n",
    "\n",
    "# The `KVPressTextGenerationPipeline` simply applies the `press` as above on the context tokens (see `_forward` method for more details).\n",
    "print(pipe(context, question=question, press=press)[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating your own press\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Updating the `score` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The easiest way to create a new press is to create a class that inherits from `BasePress` and implement a `score` method that computes the score for each key-value pair. \n",
    "\n",
    "The arguments of the `score` method are obtained from the forward hook:\n",
    "- `module`: the attention layer\n",
    "- `hidden_states`: the input of the attention layer\n",
    "- `keys` and `values`: the key-value pairs from the attention layer\n",
    "- `attentions`: the attention weights, only available with `attn_implementation=\"eager\"`\n",
    "\n",
    "In this first example, we will reproduce the `KnormPress` where the score of a key-value pair is simply the opposite of the norm of the key vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module: Qwen2FlashAttention2(\n",
      "  (q_proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
      "  (k_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "  (v_proj): Linear(in_features=1536, out_features=256, bias=True)\n",
      "  (o_proj): Linear(in_features=1536, out_features=1536, bias=False)\n",
      "  (rotary_emb): Qwen2RotaryEmbedding()\n",
      ")\n",
      "Number of key value heads: 2\n",
      "Sequence length: 44\n",
      "\n",
      "hidden_states shape: torch.Size([1, 44, 1536])\n",
      "keys shape:          torch.Size([1, 2, 44, 128])\n",
      "values shape:        torch.Size([1, 2, 44, 128])\n",
      "score shape:         torch.Size([1, 2, 44])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of this step-by-step guide is to provide instructions on how to create a new press in kvpress. The guide is designed to help users understand the process of setting up a new press in the kvpress platform.\n"
     ]
    }
   ],
   "source": [
    "class MyKnormPress(BasePress):\n",
    "    def score(\n",
    "        self,\n",
    "        module: nn.Module,\n",
    "        hidden_states: torch.Tensor,\n",
    "        keys: torch.Tensor,\n",
    "        values: torch.Tensor,\n",
    "        attentions: torch.Tensor,\n",
    "        kwargs,\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        scores = -keys.norm(dim=-1)\n",
    "\n",
    "        # For demonstration, we show some details on the shape for the first layer\n",
    "        if module.layer_idx == 0:\n",
    "            print(f\"module: {module}\")\n",
    "            print(f\"Number of key value heads: {module.num_key_value_heads}\")\n",
    "            print(f\"Sequence length: {hidden_states.shape[1]}\")\n",
    "            print()\n",
    "            print(f\"hidden_states shape: {hidden_states.shape}\")\n",
    "            print(f\"keys shape:          {keys.shape}\") # shape (bhnd)\n",
    "            print(f\"values shape:        {values.shape}\") # shape (bhnd)\n",
    "            print(f\"score shape:         {scores.shape}\") # shape (bhn)\n",
    "            print()\n",
    "        \n",
    "        return scores\n",
    "\n",
    "\n",
    "press = MyKnormPress(compression_ratio)\n",
    "print(pipe(context, question=question, press=press)[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Updating the `forward_hook` method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `forward_hook` method defined in the `BasePress` class roughly works as follows:\n",
    "\n",
    "1. Get the scores\n",
    "2. Update the key-value pairs based on the scores and the `compression_ratio`\n",
    "\n",
    "While we generally do not recommend to modify this method, the following example will show how it works. We will re-implement the `StreamingLLMPress` without using the `compression_ratio` parameter. In `StreamingLLM`, only the first `n_first` and last `n_last` key-value pairs are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_last: 2\n",
      "Last tokens seen by the model: press !\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The purpose of this guide is to provide instructions and information on how to use the software or application called \"Pulse\" or \"Pulse 2\". Pulse is a popular music production software that allows users to create, edit, and mix music tracks\n",
      "\n",
      "n_last: 4\n",
      "Last tokens seen by the model:  in kvpress !\n",
      "Answer: The purpose of this guide is to provide instructions on how to create a new content management system (CMS) called KVPress. KVPress is a content management system that allows users to easily create, edit, and publish content on their website. The guide\n",
      "\n",
      "n_last: 8\n",
      "Last tokens seen by the model:  create a new press in kvpress !\n",
      "Answer: The purpose of this guide is to provide instructions on how to create a new press in kvpress, a software tool for managing and publishing content. The guide likely covers topics such as setting up the press, configuring settings, adding content, and publishing articles\n"
     ]
    }
   ],
   "source": [
    "class MyStreamingLLMPress(BasePress):\n",
    "\n",
    "    def __init__(self, n_first=1, n_last=8):\n",
    "        self.n_first = n_first\n",
    "        self.n_last = n_last\n",
    "\n",
    "    def forward_hook(self, module: nn.Module, input: list[torch.Tensor], kwargs: dict, output: list):\n",
    "\n",
    "        # Get the cache (transformers.cache_utils.DynamicCache object)\n",
    "        cache = output[-1]\n",
    "        i = module.layer_idx\n",
    "        keys, values = cache.key_cache[i], cache.value_cache[i]\n",
    "\n",
    "        # Update the cache to only keep the first and last tokens\n",
    "        mask = torch.ones(keys.shape[-2], dtype=torch.bool, device=keys.device)\n",
    "        mask[self.n_first : -self.n_last] = False\n",
    "        cache.key_cache[i] = keys[:, :, mask, :]\n",
    "        cache.value_cache[i] = values[:, :, mask, :]\n",
    "\n",
    "        # Return the updated output (output[-1] has been modified in-place)\n",
    "        return output\n",
    "\n",
    "\n",
    "for n_last in [2, 4, 8]:\n",
    "    press = MyStreamingLLMPress(n_last=n_last)\n",
    "    print(f\"\\nn_last: {n_last}\")\n",
    "    print(f\"Last tokens seen by the model: {pipe.tokenizer.decode(tokens.input_ids[0, -n_last:])}\")\n",
    "    print(f\"Answer: {pipe(context, question=question, press=press)['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Contributing to kvpress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All presses should be stored in the `presses` directory. Before opening a pull request with your new press, make sure to register it in the `__init__.py` file of repository and to add it in [test_presses.py](tests/presses/test_presses.py). We recommend not to update the `forward_hook` or `__call__` method unless necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
